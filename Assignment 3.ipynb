{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f328d-94d4-441a-a73b-f26ac92c6fe8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "#------Author- Jay Shah------\n",
    "#------Date-02/23/24---------\n",
    "#------Assignment 3----------\n",
    "\n",
    "#-------Description-------\n",
    "#------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c0203-745a-4e9e-894a-8658cea2ac68",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91d0ccd3-d888-4061-bf2e-f0ed950e9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e2969-3319-4dc6-8264-35652ac9aa2a",
   "metadata": {},
   "source": [
    "Path training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8d0888a-a129-4983-841c-7bf347eaf5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/Users/jayshah/Downloads/Assigment3/Train'\n",
    "validation_data_dir = '/Users/jayshah/Downloads/Assigment3/Validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaadcc2b-020d-44ed-a2b7-e1596e0f678c",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a160575-77ac-4081-b2da-799ec90cfe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69529d57-2df9-427f-a062-5a3f026bde9e",
   "metadata": {},
   "source": [
    "Data Generator for training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17fdc6aa-0fb8-495a-8a34-eb7e15f15372",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "valid_data_gen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "479bf032-29e7-4db3-bf9d-e35cfb940081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1101 images belonging to 10 classes.\n",
      "Found 10 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_data = valid_data_gen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd959db-2dc1-4e0d-a56d-21a081ea7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5e3d752-363d-417f-af7d-8e506e0ac691",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59480fbe-4c6e-4fba-bdd4-182a783bb87c",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ed5b4b5-ba82-46fe-a2da-8626aa35473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d984d4d1-94b9-425e-8307-9fa114d9a055",
   "metadata": {},
   "source": [
    "TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6127393-2951-4077-a5ba-fd3f366871bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fac9cd-2631-4613-bec6-828b6017ac17",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b69d5344-f76b-40e3-9f89-7b2b56ae612e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 12s 332ms/step - loss: 2.2226 - accuracy: 0.1926 - val_loss: 2.9732 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 11s 303ms/step - loss: 1.7800 - accuracy: 0.3724 - val_loss: 3.5339 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 11s 299ms/step - loss: 1.5273 - accuracy: 0.4578 - val_loss: 3.5044 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 10s 293ms/step - loss: 1.3216 - accuracy: 0.5595 - val_loss: 4.7149 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 11s 304ms/step - loss: 1.0273 - accuracy: 0.6349 - val_loss: 4.2585 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 12s 338ms/step - loss: 0.7775 - accuracy: 0.7248 - val_loss: 4.8646 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 12s 339ms/step - loss: 0.5834 - accuracy: 0.8011 - val_loss: 5.9243 - val_accuracy: 0.2000\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 12s 333ms/step - loss: 0.4077 - accuracy: 0.8629 - val_loss: 6.0332 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 11s 317ms/step - loss: 0.2111 - accuracy: 0.9373 - val_loss: 7.6509 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 11s 313ms/step - loss: 0.1448 - accuracy: 0.9609 - val_loss: 9.4405 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29c089910>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=epochs, validation_data=validation_data, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a6f3d-5e6c-4fc1-a1e0-b6727f527517",
   "metadata": {},
   "source": [
    "saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6311a9a9-c7cc-448d-815d-dc2089f302ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('paintings_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce32f15-eea1-42fb-9807-93f3b7194fcb",
   "metadata": {},
   "source": [
    "Predicting the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cacd81d4-2fa3-4894-914c-d3ba115ae042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f6debf9-4a9f-4bd2-a47c-2038645f7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('paintings_classification_model.h5')\n",
    "\n",
    "#the directory where images are \n",
    "sample_images_dir = '/Users/jayshah/Downloads/Assigment3/Sample_Data/'\n",
    "\n",
    "# image files\n",
    "image_filenames = [\n",
    "    'Rene_Magritte_18.jpg', 'Amedeo_Modigliani_101.jpg', 'Amedeo_Modigliani_100.jpg',\n",
    "    'Amedeo_Modigliani_99.jpg', 'Amedeo_Modigliani_98.jpg', 'Amedeo_Modigliani_97.jpg',\n",
    "    'Vincent_van_Gogh_108.jpg', 'Vincent_van_Gogh_107.jpg', 'Vincent_van_Gogh_106.jpg',\n",
    "    'Vincent_van_Gogh_105.jpg', 'Rene_Magritte_17.jpg', 'Rene_Magritte_3.jpg', 'Titian_15.jpg',\n",
    "    'Titian_14.jpg', 'Paul_Gauguin_30.jpg', 'Paul_Gauguin_29.jpg', 'Edgar_Degas_6.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b46e95d-393e-49fa-ab41-5e80f75b005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "Image: Rene_Magritte_18.jpg, Predicted Class: Rene_Magritte\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Image: Amedeo_Modigliani_101.jpg, Predicted Class: Amedeo_Modigliani\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Image: Amedeo_Modigliani_100.jpg, Predicted Class: Amedeo_Modigliani\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Image: Amedeo_Modigliani_99.jpg, Predicted Class: Amedeo_Modigliani\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Image: Amedeo_Modigliani_98.jpg, Predicted Class: Amedeo_Modigliani\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Image: Amedeo_Modigliani_97.jpg, Predicted Class: Amedeo_Modigliani\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Image: Vincent_van_Gogh_108.jpg, Predicted Class: Vincent_van_Gogh\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Image: Vincent_van_Gogh_107.jpg, Predicted Class: Vincent_van_Gogh\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Image: Vincent_van_Gogh_106.jpg, Predicted Class: Vincent_van_Gogh\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Image: Vincent_van_Gogh_105.jpg, Predicted Class: Vincent_van_Gogh\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Image: Rene_Magritte_17.jpg, Predicted Class: Rene_Magritte\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Image: Rene_Magritte_3.jpg, Predicted Class: Pablo_Picasso\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Image: Titian_15.jpg, Predicted Class: Titian\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Image: Titian_14.jpg, Predicted Class: Titian\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Image: Paul_Gauguin_30.jpg, Predicted Class: Paul_Gauguin\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Image: Paul_Gauguin_29.jpg, Predicted Class: Paul_Gauguin\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Image: Edgar_Degas_6.jpg, Predicted Class: Edgar_Degas\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('paintings_classification_model.h5')\n",
    "\n",
    "#the directory where images are \n",
    "sample_images_dir = '/Users/jayshah/Downloads/Assigment3/Sample_Data/'\n",
    "\n",
    "# image files\n",
    "image_filenames = [\n",
    "    'Rene_Magritte_18.jpg', 'Amedeo_Modigliani_101.jpg', 'Amedeo_Modigliani_100.jpg',\n",
    "    'Amedeo_Modigliani_99.jpg', 'Amedeo_Modigliani_98.jpg', 'Amedeo_Modigliani_97.jpg',\n",
    "    'Vincent_van_Gogh_108.jpg', 'Vincent_van_Gogh_107.jpg', 'Vincent_van_Gogh_106.jpg',\n",
    "    'Vincent_van_Gogh_105.jpg', 'Rene_Magritte_17.jpg', 'Rene_Magritte_3.jpg', 'Titian_15.jpg',\n",
    "    'Titian_14.jpg', 'Paul_Gauguin_30.jpg', 'Paul_Gauguin_29.jpg', 'Edgar_Degas_6.jpg'\n",
    "]\n",
    "\n",
    "# Iterate through each image filename\n",
    "for filename in image_filenames:\n",
    "    # Construct the full path to the image\n",
    "    img_path = os.path.join(sample_images_dir, filename)\n",
    "    \n",
    "    # Check if the image file exists\n",
    "    if os.path.exists(img_path):\n",
    "        # Load and preprocess the image\n",
    "        img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "\n",
    "        # Make predictions using the model\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class_index = np.argmax(predictions)\n",
    "        predicted_class = list(train_data.class_indices.keys())[predicted_class_index]\n",
    "\n",
    "        print(f\"Image: {filename}, Predicted Class: {predicted_class}\")\n",
    "    else:\n",
    "        print(f\"Image file {filename} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678a5bf-eddd-4211-a5af-67041424a157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
